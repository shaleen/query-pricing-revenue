\section{Introduction}
\label{sec:intro}

The last decade or so has seen an explosion of data being collected from a variety of sources and across a broad range of areas. Many companies, including Bloomberg~\cite{bloomberg}, Twitter~\cite{twitterapi}, Lattice Data~\cite{lattice}, DataFinder~\cite{datafinder}, and Banjo~\cite{banjo} collect such data, which then sell as structured (relational) datasets. 
These datasets are also often sold through online {\em data markets}, which are web platforms for buying and selling data: examples include BDEX~\cite{bdex}, Salesforce~\cite{salesforce} and QLik DataMarket~\cite{qlik}. Even though data sellers and data markets offer an abundance of data products, the pricing schemes currently used are very simplistic. In most cases, a data buyer has only one option, to buy the whole dataset (or a bundle of datasets) at a fixed price. Alternatively, the dataset is split into multiple disjoint chunks, and each chunk is sold at a separate price. 

However, data buyers are commonly interested in extracting specific information from a dataset, and not in acquiring the whole dataset. Accessing this information can be often concisely captured through a {\em query}, or a sequence of queries. Selling the whole dataset to a fixed price forces the buyer to either pay for the query more than it is valued, or to choose to not access it. This means that valuable data is often not accessible to lay users, scientists, or entities with limited budgets, and moreover that data-selling companies and marketplaces behave suboptimally with respect to maximizing their revenue.

To address this problem, a recent line of research~\cite{KUBHS12,KUBHS13,deep2017qirana} in the database community introduced the framework of  query-based pricing. A {\em query-based pricing scheme} tailors the purchase of the data to the user's needs, by assigning a price to each query issued over the dataset. Given a dataset $\db$ and a query $Q$ over the dataset, the user must pay a price $p(Q,\db)$ to obtain the answer $Q(\db)$ of the query. This price reflects only the value of the information learned by obtaining the query answer, and not the computational cost of executing the query. The work on query-based pricing has mainly focused on how one can define a well-behaved pricing function, and to how to compute it efficiently. In particular, a key property that a pricing function must obey is that of {\em arbitrage freeness}: it should not be possible for the buyer to acquire a query for a cheaper price through the combination of other query results. This is a type of incentive constraint. The arbitrage-freeness constraint makes the design of appropriate pricing functions a challenging task, especially since deciding whether a query is more informative than another query (or set of queries) is generally a computationally hard problem, and for practical applications it is critical that the price computation can be performed efficiently.

To overcome this computational barrier, \citet{deep2017qirana} propose a setup where the seller and buyers have a common knowledge base $\mI$ consisting of multiple potential datasets. Each query (or set of queries) can then be thought of as a function that classifies datasets. The answer to a query identifies the collection of datasets in $\mI$ that are consistent with that answer. Whether a query is more informative than another then amounts to whether it identifies more inconsistent datasets than the latter. The benefit of this restricted model is that the query pricing can now be cast as a problem of pricing subsets over a ground set of items, each item being a dataset in the knowledge base $\mI$. The arbitrage-freeness constraint corresponds to the pricing function being subadditive. Of course, finding the optimal subadditive pricing is also a computationally hard problem. Furthermore, a general subadditive function, even if we manage to find one, can take exponential space to store. We therefore ask whether it is possible to find a simple pricing function that approximates the optimal subadditive pricing in terms of the seller's revenue. Observe that in the query pricing setting, there is no cost to the seller for replicating answers to queries, and so we can model the seller as having {\em unlimited supply} for each item. We further assume that buyers are single minded -- each buyer wants to buy the answer to a single query.

% To overcome this computational barrier, one possible solution proposed in~\cite{deep2017qirana}  is to model each query $Q$ as a {\em bundle} of items $B(Q)$ from a common itemset $I$. Then, the arbitrage-free constraint translates to the requirement that the pricing function must be {\em monotone} and {\em subadditive} when viewed as a set function. Among such set functions, of particular practical interest are the additive and constant functions. An additive function gives to each item $i \in I$  a weight $w_i \geq 0$, and assigns the price $p(Q,\db) = \sum_{i \in B(Q)} w_i$, while a constant function simply assigns the same  price to every query, \ie $p(Q,\db) = p$.
% However, prior work has not answered the fundamental question of how one can choose among the possible set functions (or subclasses of them) the one that maximizes the revenue of the seller. 

Revenue maximization with unlimited supply and single-minded buyers has been studied extensively from a theoretical perspective~\cite{guruswami2005profit,balcan2006approximation,briest2006single}. This literature aims to obtain worst case approximation guarantees for revenue using additive pricing functions, a.k.a. item pricing. An item pricing gives to each item $i$  a weight $w_i \geq 0$, and assigns the price $p(S) = \sum_{i \in S} w_i$ to a bundle $S$ of items. There are a number of different algorithms and corresponding analyses in literature that produce item pricings with worst case approximation factors logarithmic in one or more of the natural parameters of the instance---the number of items $n$, the number of bundles $m$, the size of the largest bundle $k$, and the maximum number of bundles any item belongs to $B$. Many of these analyses are tight to within constant factors in the worst case. But how well do these approximation results hold up in practice? Does the seller really need to give up on all but a logarithmic fraction of the optimal revenue in order to gain computational efficiency? Which of these algorithms should a practitioner use, and what features of the problem instance dictate this choice? These are some of the questions we study in this paper.

\vspace{1em}
{\em The goal of this work is to investigate whether theoretical performance bounds for revenue maximization with unlimited supply hold up in practice, using as an application the setting of query pricing for data markets.} We perform an experimental study to evaluate the quality of various pricing algorithms for different problem instances, both synthetic and real. The approximation ratio of a pricing algorithm is just one of many features that determine how practical the algorithm is. We compare algorithms in terms of the revenue obtained, as well as their running time and the representation complexity of the pricing produced. \paris{What about the lower bound?}

We study the performance of three different pricing algorithms in this paper. The first is an item pricing algorithm due to Cheung and Swamy~\cite{cheung2008approximation} that achieves the best known worst case approximation ratio for revenue, namely $O(\log B)$. This algorithm involves solving multiple linear programs for each instance of the problem, and is therefore very slow in practice. The second algorithm we consider is an item pricing with a worse approximation ratio of $O(\log n+\log m)$. This is a simple algorithm that produces a uniform item pricing, namely one where all item weights, $w_i$, are equal. The simplicity of the algorithm allows for algorithmic improvements that do not hurt its approximation ratio but for some instances can greatly improve performance. We describe one such improvement in Section~\ref{section-approxalgo}. The third algorithm we study is an extremely fast greedy item pricing algorithm. We show in Section~\ref{section-approxalgo} that the greedy algorithm achieves a worst case approximation factor of $O(B)$. Although this approximation factor is exponentially worse than that of the first algorithm, we observe that for many workloads the two algorithms achieve similar performance, and the simplicity and speed of the greedy algorithm gives it a distinct advantage. For the sake of comparison, we also implement and report results for a constant pricing function, namely one that assigns the same price to every bundle (query). \todo{Say something about XOS?}

Our experimental study shows that the worst-case analysis of pricing algorithms does not capture how well the algorithms behave in real-world instances in terms of approximating the optimal revenue, for the specific application of query-based pricing. In particular, we observe that the structure of the bundles induced by different query workloads heavily influences the quality of approximation. Our work suggests that a promising direction is to attempt to obtain better approximation guarantees by taking into account the structure of the bundles, and also the type of valuations that occur in real-world settings.

% In this paper, we tackle the above question building on ideas from the optimal pricing 
% literature~\cite{guruswami2005profit}. We consider the {\em unlimited supply} setting, where the 
% seller can sell any number of units of each query. This is a natural assumption in the context of a data market,
% since multiple buyers can request and purchase the same query.
% Additionally, we assume that the buyers are {\em single-minded}, so each
% buyer is interested in buying only a single query $Q$ (so a single bundle) for a price of $v_Q$; the buyer will
% purchase the query only if the price $p(Q, \db)$ does not exceed $v_Q$. We focus on the aforementioned two
% types of pricing functions that either assign a uniform price to every query, or perform item pricing. 
% In the case of item pricing, the problem of computing the revenue-maximizing prices can be cast as
% the well-studied {\em hypergraph vertex pricing} problem, where only approximation guarantees are known.










